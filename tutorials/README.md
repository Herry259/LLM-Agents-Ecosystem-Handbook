# Tutorials Overview

The `tutorials` folder contains step‑by‑step guides to help you build your own
LLM applications.  These tutorials complement the code skeletons in the
`examples` directory and cover core topics such as retrieval‑augmented
generation, memory, conversational interfaces over custom data sources and
fine‑tuning.  Each subfolder includes a README with background concepts,
setup instructions and links to relevant skeletons.

## Available tutorials

- **Quick Start** – [`quickstart.md`](quickstart.md) is a short guide on
  cloning the repository, installing dependencies and running your first
  agent.
- **RAG Tutorials** – [`rag_tutorials`](rag_tutorials) explains how to
  implement retrieval‑augmented generation pipelines, index documents and
  integrate retrieval into your agents.
- **Memory Apps Tutorials** – [`memory_apps`](memory_apps) introduces
  techniques for adding memory and state to your LLM applications.
- **Chat with X Tutorials** – [`chat_with_x_tutorials`](chat_with_x_tutorials)
  shows how to build conversational interfaces over data sources like
  GitHub, email, PDFs, research papers, Substack and YouTube.
- **LLM Fine‑Tuning Tutorials** – [`fine_tuning_tutorials`](fine_tuning_tutorials)
  covers when and how to fine‑tune models, including parameter‑efficient
  techniques and evaluation tips.

Feel free to contribute new tutorials or improve existing ones!  Open an
issue or pull request to share your ideas and help others learn.
